{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6980e0e6",
   "metadata": {},
   "source": [
    "# DeepRoof Checkpoint Inference\n",
    "\n",
    "Runs full segmentation + geometry inference on any satellite image.\n",
    "\n",
    "**Output per roof instance:**\n",
    "- Semantic class (flat / sloped)\n",
    "- Instance mask + polygon\n",
    "- Surface normal vector (nx, ny, nz)\n",
    "- Slope angle in degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== CONFIGURATION ========================\n",
    "MODEL_INPUT_SIZE = 512  # Training resolution (native OmniCity size)\n",
    "MASK_THRESHOLD = 0.5    # Min sigmoid confidence for a pixel to be non-background\n",
    "\n",
    "\n",
    "def detect_project_root() -> Path:\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        Path.cwd().parent,\n",
    "        Path('/workspace/roof'),\n",
    "        Path('/Users/voskan/Desktop/DeepRoof-2026'),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if (c / 'configs').exists() and (c / 'deeproof').exists():\n",
    "            return c\n",
    "    raise FileNotFoundError('Could not auto-detect project root.')\n",
    "\n",
    "\n",
    "def resolve_checkpoint(work_dir: Path, fallback_ckpt: Path) -> Path:\n",
    "    last_ckpt_ptr = work_dir / 'last_checkpoint'\n",
    "    if last_ckpt_ptr.exists():\n",
    "        target = last_ckpt_ptr.read_text(encoding='utf-8').strip()\n",
    "        if target:\n",
    "            t = Path(target)\n",
    "            if not t.is_absolute():\n",
    "                t = work_dir / t\n",
    "            if t.exists():\n",
    "                return t\n",
    "    return fallback_ckpt\n",
    "\n",
    "\n",
    "PROJECT_ROOT = detect_project_root()\n",
    "CONFIG_PATH = PROJECT_ROOT / 'configs' / 'deeproof_production_swin_L.py'\n",
    "\n",
    "WORK_DIR = PROJECT_ROOT / 'work_dirs' / 'swin_l_scratch_v1'\n",
    "SERVER_CHECKPOINT_PATH = WORK_DIR / 'iter_16000.pth'\n",
    "LOCAL_ANALYSIS_CHECKPOINT_PATH = Path('/Users/voskan/Downloads/iter_16000.pth')\n",
    "CHECKPOINT_PATH = resolve_checkpoint(WORK_DIR, SERVER_CHECKPOINT_PATH)\n",
    "if not CHECKPOINT_PATH.exists() and LOCAL_ANALYSIS_CHECKPOINT_PATH.exists():\n",
    "    CHECKPOINT_PATH = LOCAL_ANALYSIS_CHECKPOINT_PATH\n",
    "\n",
    "INPUT_IMAGE_PATH = Path('/workspace/test.png')\n",
    "if not INPUT_IMAGE_PATH.exists():\n",
    "    fallback = PROJECT_ROOT / 'test.png'\n",
    "    if fallback.exists():\n",
    "        INPUT_IMAGE_PATH = fallback\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs' / 'checkpoint_inference'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OVERLAY_PATH = OUTPUT_DIR / 'test_segmentation_overlay.png'\n",
    "SEM_MASK_PATH = OUTPUT_DIR / 'test_semantic_mask.png'\n",
    "SUMMARY_PATH = OUTPUT_DIR / 'test_inference_summary.json'\n",
    "POLYGONS_JSON_PATH = OUTPUT_DIR / 'test_roof_polygons.json'\n",
    "POLYGONS_GEOJSON_PATH = OUTPUT_DIR / 'test_roof_polygons.geojson'\n",
    "PREPROCESSED_PATH = OUTPUT_DIR / 'test_preprocessed.png'\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'CHECKPOINT: {CHECKPOINT_PATH}')\n",
    "print(f'INPUT: {INPUT_IMAGE_PATH}')\n",
    "print(f'MODEL_INPUT_SIZE: {MODEL_INPUT_SIZE}, MASK_THRESHOLD: {MASK_THRESHOLD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== IMAGE PREPROCESSING ========================\n",
    "for p in (CONFIG_PATH, CHECKPOINT_PATH, INPUT_IMAGE_PATH):\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f'Path not found: {p}')\n",
    "\n",
    "img_orig_bgr = cv2.imread(str(INPUT_IMAGE_PATH), cv2.IMREAD_COLOR)\n",
    "if img_orig_bgr is None:\n",
    "    raise RuntimeError(f'Could not load image: {INPUT_IMAGE_PATH}')\n",
    "\n",
    "orig_h, orig_w = img_orig_bgr.shape[:2]\n",
    "\n",
    "# Center-crop to square, then resize to training resolution\n",
    "crop_size = min(orig_h, orig_w)\n",
    "y_start = (orig_h - crop_size) // 2\n",
    "x_start = (orig_w - crop_size) // 2\n",
    "img_cropped = img_orig_bgr[y_start:y_start+crop_size, x_start:x_start+crop_size]\n",
    "img_bgr = cv2.resize(img_cropped, (MODEL_INPUT_SIZE, MODEL_INPUT_SIZE), interpolation=cv2.INTER_AREA)\n",
    "cv2.imwrite(str(PREPROCESSED_PATH), img_bgr)\n",
    "print(f'Preprocessed: {orig_w}x{orig_h} -> crop {crop_size}x{crop_size} -> {MODEL_INPUT_SIZE}x{MODEL_INPUT_SIZE}')\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "H, W = img_rgb.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== LOAD MODEL ========================\n",
    "os.environ.setdefault('TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD', '1')\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from mmseg.utils import register_all_modules\n",
    "from mmseg.apis import init_model\n",
    "from mmengine.config import ConfigDict\n",
    "from mmengine.dataset import Compose\n",
    "\n",
    "register_all_modules(init_default_scope=False)\n",
    "\n",
    "import deeproof.models.backbones.swin_v2_compat\n",
    "import deeproof.models.deeproof_model\n",
    "import deeproof.models.heads.mask2former_head\n",
    "import deeproof.models.heads.geometry_head\n",
    "import deeproof.models.losses\n",
    "\n",
    "model = init_model(str(CONFIG_PATH), str(CHECKPOINT_PATH), device=DEVICE)\n",
    "model.test_cfg = ConfigDict(dict(mode='whole'))\n",
    "model.eval()\n",
    "print('Model loaded successfully.')\n",
    "print(f'Has geometry_head: {hasattr(model, \"geometry_head\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== FORWARD PASS + GEOMETRY ========================\n",
    "# Run backbone + decode_head + geometry_head manually\n",
    "# (we bypass inference_model to use panoptic-style post-processing)\n",
    "\n",
    "test_pipeline = model.cfg.get('test_pipeline', [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(MODEL_INPUT_SIZE, MODEL_INPUT_SIZE), keep_ratio=False),\n",
    "    dict(type='PackSegInputs'),\n",
    "])\n",
    "pipeline = Compose(test_pipeline)\n",
    "data = pipeline(dict(img_path=str(PREPROCESSED_PATH)))\n",
    "\n",
    "data_batch = dict(\n",
    "    inputs=[data['inputs']],\n",
    "    data_samples=[data['data_samples']],\n",
    ")\n",
    "data_batch = model.data_preprocessor(data_batch, False)\n",
    "inputs = data_batch['inputs']\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 1. Backbone features\n",
    "    x = model.extract_feat(inputs)\n",
    "    \n",
    "    # 2. Mask2Former decode head → cls_scores + mask_preds + query embeddings\n",
    "    all_cls_scores, all_mask_preds = model.decode_head(x, data_batch['data_samples'])\n",
    "    \n",
    "    # 3. GeometryHead → surface normals per query\n",
    "    query_embeddings = getattr(model.decode_head, 'last_query_embeddings', None)\n",
    "    geo_preds = None  # [B, Q, 3] predicted normals\n",
    "    if query_embeddings is not None and hasattr(model, 'geometry_head'):\n",
    "        # Normalize query embeddings (same as model.predict does)\n",
    "        qe = query_embeddings\n",
    "        if isinstance(qe, (list, tuple)):\n",
    "            qe = qe[-1]\n",
    "        if qe.ndim == 4:\n",
    "            qe = qe[-1]\n",
    "        if qe.ndim == 2:\n",
    "            qe = qe.unsqueeze(0)\n",
    "        geo_preds = model.geometry_head(qe)  # [B, Q, 3] unit normals\n",
    "        print(f'GeometryHead output: {geo_preds.shape}')\n",
    "    else:\n",
    "        print('WARNING: query_embeddings not available — geometry predictions skipped')\n",
    "\n",
    "# Last decoder layer (most refined)\n",
    "cls_scores = all_cls_scores[-1][0]   # [Q, C+1]\n",
    "mask_preds = all_mask_preds[-1][0]   # [Q, h, w]\n",
    "\n",
    "num_queries = cls_scores.shape[0]\n",
    "num_classes = cls_scores.shape[1] - 1\n",
    "print(f'cls_scores: {cls_scores.shape}, mask_preds: {mask_preds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== PANOPTIC-STYLE SEMANTIC MAP ========================\n",
    "cls_probs = torch.softmax(cls_scores, dim=-1)  # [Q, C+1]\n",
    "obj_probs = cls_probs[:, :-1]                   # [Q, C]\n",
    "no_obj_probs = cls_probs[:, -1]                  # [Q]\n",
    "mask_sigmoid = mask_preds.sigmoid()              # [Q, h, w]\n",
    "\n",
    "# Per-query: best class and confidence\n",
    "query_class = obj_probs.argmax(dim=-1)           # [Q]\n",
    "query_obj_confidence = obj_probs.max(dim=-1).values  # [Q]\n",
    "\n",
    "# Per-pixel: combined score = P(class) * sigmoid(mask)\n",
    "pixel_scores = query_obj_confidence.unsqueeze(-1).unsqueeze(-1) * mask_sigmoid\n",
    "best_score_per_pixel, best_query_per_pixel = pixel_scores.max(dim=0)\n",
    "\n",
    "# Assign class from winning query\n",
    "sem_map_lowres = query_class[best_query_per_pixel]\n",
    "\n",
    "# Background: where no mask is confident enough\n",
    "best_mask_per_pixel = mask_sigmoid.max(dim=0).values\n",
    "sem_map_lowres[best_mask_per_pixel < MASK_THRESHOLD] = 0\n",
    "\n",
    "# Upscale to image resolution\n",
    "sem_map = F.interpolate(\n",
    "    sem_map_lowres.float().unsqueeze(0).unsqueeze(0),\n",
    "    size=(H, W), mode='nearest'\n",
    ")[0, 0].long().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "# Also create per-pixel query assignment map (upscaled) for geometry lookup\n",
    "query_map = F.interpolate(\n",
    "    best_query_per_pixel.float().unsqueeze(0).unsqueeze(0),\n",
    "    size=(H, W), mode='nearest'\n",
    ")[0, 0].long().cpu().numpy()\n",
    "\n",
    "unique_classes = np.unique(sem_map).tolist()\n",
    "class_areas = {int(c): float((sem_map == c).sum()) / float(sem_map.size) for c in unique_classes}\n",
    "roof_ratio = float((sem_map > 0).sum()) / float(sem_map.size)\n",
    "\n",
    "print(f'Semantic classes: {unique_classes}')\n",
    "print(f'Class areas: {class_areas}')\n",
    "print(f'Roof pixel ratio: {roof_ratio:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e3f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== BUILD INSTANCES WITH GEOMETRY ========================\n",
    "instances = []  # List of dicts with mask, class, score, normal, slope\n",
    "MIN_AREA = 64\n",
    "\n",
    "# Get per-query normals from GeometryHead\n",
    "query_normals = geo_preds[0].cpu().numpy() if geo_preds is not None else None  # [Q, 3]\n",
    "\n",
    "for cls_id in np.unique(sem_map):\n",
    "    cls_id = int(cls_id)\n",
    "    if cls_id <= 0 or cls_id == 255:\n",
    "        continue\n",
    "    binary = (sem_map == cls_id).astype(np.uint8)\n",
    "    num_comp, comp = cv2.connectedComponents(binary, connectivity=8)\n",
    "    for comp_id in range(1, int(num_comp)):\n",
    "        m = (comp == comp_id)\n",
    "        area = int(m.sum())\n",
    "        if area < MIN_AREA:\n",
    "            continue\n",
    "        \n",
    "        # Score: mean mask sigmoid in this region\n",
    "        m_lowres = cv2.resize(m.astype(np.uint8), (mask_sigmoid.shape[-1], mask_sigmoid.shape[-2]),\n",
    "                              interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        mean_conf = float(mask_sigmoid.max(dim=0).values[torch.from_numpy(m_lowres)].mean())\n",
    "        \n",
    "        # Geometry: find the dominant query in this region and get its normal\n",
    "        region_queries = query_map[m]  # query indices for all pixels in this instance\n",
    "        dominant_query = int(np.bincount(region_queries).argmax())  # most common query\n",
    "        \n",
    "        normal = None\n",
    "        slope_deg = None\n",
    "        azimuth_deg = None\n",
    "        if query_normals is not None:\n",
    "            normal = query_normals[dominant_query]  # [3] = (nx, ny, nz)\n",
    "            # Slope = angle from vertical (Z axis)\n",
    "            nz = float(np.clip(normal[2], -1.0, 1.0))\n",
    "            slope_deg = float(np.degrees(np.arccos(abs(nz))))\n",
    "            # Azimuth = compass direction the slope faces (from nx, ny)\n",
    "            nx, ny = float(normal[0]), float(normal[1])\n",
    "            azimuth_deg = float(np.degrees(np.arctan2(ny, nx))) % 360\n",
    "        \n",
    "        instances.append({\n",
    "            'mask': m,\n",
    "            'class_id': cls_id,\n",
    "            'class_name': {0: 'background', 1: 'flat_roof', 2: 'sloped_roof'}.get(cls_id, f'class_{cls_id}'),\n",
    "            'score': mean_conf,\n",
    "            'area_px': area,\n",
    "            'dominant_query': dominant_query,\n",
    "            'normal': normal.tolist() if normal is not None else None,\n",
    "            'slope_deg': slope_deg,\n",
    "            'azimuth_deg': azimuth_deg,\n",
    "        })\n",
    "\n",
    "print(f'\\n=== DETECTED ROOF INSTANCES: {len(instances)} ===')\n",
    "print(f'{\"#\":>3} {\"Class\":>12} {\"Slope°\":>7} {\"Azimuth°\":>9} {\"Normal (nx,ny,nz)\":>25} {\"Score\":>6} {\"Area\":>8}')\n",
    "print('-' * 80)\n",
    "for i, inst in enumerate(instances):\n",
    "    n_str = f'({inst[\"normal\"][0]:+.3f}, {inst[\"normal\"][1]:+.3f}, {inst[\"normal\"][2]:+.3f})' if inst['normal'] else 'N/A'\n",
    "    s_str = f'{inst[\"slope_deg\"]:.1f}' if inst['slope_deg'] is not None else 'N/A'\n",
    "    a_str = f'{inst[\"azimuth_deg\"]:.0f}' if inst['azimuth_deg'] is not None else 'N/A'\n",
    "    print(f'{i:3d} {inst[\"class_name\"]:>12} {s_str:>7} {a_str:>9} {n_str:>25} {inst[\"score\"]:6.3f} {inst[\"area_px\"]:8d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== VISUALIZATION ========================\n",
    "palette = np.array([\n",
    "    [0, 0, 0],       # 0: background\n",
    "    [0, 255, 0],     # 1: flat_roof\n",
    "    [255, 0, 0],     # 2: sloped_roof\n",
    "], dtype=np.uint8)\n",
    "\n",
    "sem_vis = palette[np.clip(sem_map, 0, len(palette) - 1)]\n",
    "overlay = cv2.addWeighted(img_rgb, 0.60, sem_vis, 0.40, 0.0)\n",
    "\n",
    "# Extract polygons and draw with slope/azimuth labels\n",
    "roof_polygons = []\n",
    "MIN_POLY_AREA = 64\n",
    "\n",
    "for i, inst in enumerate(instances):\n",
    "    contours, _ = cv2.findContours(inst['mask'].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = float(cv2.contourArea(contour))\n",
    "        if area < MIN_POLY_AREA:\n",
    "            continue\n",
    "        epsilon = 0.003 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        poly = approx.reshape(-1, 2)\n",
    "        if poly.shape[0] < 3:\n",
    "            continue\n",
    "\n",
    "        poly_data = {\n",
    "            'polygon_id': len(roof_polygons),\n",
    "            'class_id': inst['class_id'],\n",
    "            'class_name': inst['class_name'],\n",
    "            'score': inst['score'],\n",
    "            'area_px': area,\n",
    "            'slope_deg': inst['slope_deg'],\n",
    "            'azimuth_deg': inst['azimuth_deg'],\n",
    "            'normal': inst['normal'],\n",
    "            'points_xy': poly.astype(int).tolist(),\n",
    "        }\n",
    "        roof_polygons.append(poly_data)\n",
    "\n",
    "# Draw polygons with slope labels\n",
    "for poly_obj in roof_polygons:\n",
    "    pts = np.array(poly_obj['points_xy'], dtype=np.int32).reshape(-1, 1, 2)\n",
    "    color = (0, 255, 0) if poly_obj['class_id'] == 1 else (255, 100, 100)\n",
    "    cv2.polylines(overlay, [pts], True, (255, 255, 255), 2)\n",
    "    \n",
    "    m = cv2.moments(pts)\n",
    "    if m['m00'] > 0:\n",
    "        cx, cy = int(m['m10'] / m['m00']), int(m['m01'] / m['m00'])\n",
    "    else:\n",
    "        cx, cy = int(pts[0, 0, 0]), int(pts[0, 0, 1])\n",
    "    \n",
    "    # Label with slope angle\n",
    "    if poly_obj['slope_deg'] is not None:\n",
    "        txt = f\"{poly_obj['slope_deg']:.0f}deg\"\n",
    "    else:\n",
    "        txt = poly_obj['class_name']\n",
    "    cv2.putText(overlay, txt, (cx - 15, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "# Save\n",
    "cv2.imwrite(str(OVERLAY_PATH), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(str(SEM_MASK_PATH), sem_map)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(f'Input ({W}x{H})')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(sem_vis)\n",
    "plt.title(f'Semantic (bg={class_areas.get(0,0):.0%}, roof={roof_ratio:.0%})')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(overlay)\n",
    "plt.title(f'{len(roof_polygons)} roof planes with slope angles')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nSaved overlay: {OVERLAY_PATH}')\n",
    "print(f'Total roof polygons: {len(roof_polygons)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== TOP-6 QUERY MASKS ========================\n",
    "sorted_idx = query_obj_confidence.argsort(descending=True)\n",
    "top_queries = sorted_idx[:6]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for idx, qi in enumerate(top_queries):\n",
    "    qi = int(qi)\n",
    "    ax = axes[idx // 3][idx % 3]\n",
    "    mask_vis = mask_sigmoid[qi].cpu().numpy()\n",
    "    ax.imshow(mask_vis, cmap='hot', vmin=0, vmax=1)\n",
    "    cov = float((mask_sigmoid[qi] > 0.5).float().mean())\n",
    "    n_str = ''\n",
    "    if query_normals is not None:\n",
    "        n = query_normals[qi]\n",
    "        slope = float(np.degrees(np.arccos(np.clip(abs(n[2]), -1, 1))))\n",
    "        n_str = f', slope={slope:.0f}°'\n",
    "    ax.set_title(f'Q{qi}: cls={int(query_class[qi])}, cov={cov:.3f}{n_str}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Top 6 query masks (sigmoid) + slope angles', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccece88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== SAVE JSON OUTPUT ========================\n",
    "# Full JSON with polygons + geometry\n",
    "json_polygons = []\n",
    "for p in roof_polygons:\n",
    "    json_polygons.append({k: v for k, v in p.items() if k != 'mask'})\n",
    "\n",
    "with POLYGONS_JSON_PATH.open('w', encoding='utf-8') as f:\n",
    "    json.dump({\n",
    "        'image': str(INPUT_IMAGE_PATH),\n",
    "        'checkpoint': str(CHECKPOINT_PATH),\n",
    "        'model_input_size': MODEL_INPUT_SIZE,\n",
    "        'mask_threshold': MASK_THRESHOLD,\n",
    "        'polygons': json_polygons,\n",
    "    }, f, indent=2)\n",
    "\n",
    "# GeoJSON\n",
    "geojson = {'type': 'FeatureCollection', 'features': []}\n",
    "for p in roof_polygons:\n",
    "    coords = [[float(x), float(y)] for x, y in p['points_xy']]\n",
    "    if coords and coords[0] != coords[-1]:\n",
    "        coords.append(coords[0])\n",
    "    geojson['features'].append({\n",
    "        'type': 'Feature',\n",
    "        'properties': {\n",
    "            'polygon_id': p['polygon_id'],\n",
    "            'class_name': p['class_name'],\n",
    "            'slope_deg': p['slope_deg'],\n",
    "            'azimuth_deg': p['azimuth_deg'],\n",
    "            'normal': p['normal'],\n",
    "            'score': p['score'],\n",
    "        },\n",
    "        'geometry': {'type': 'Polygon', 'coordinates': [coords]},\n",
    "    })\n",
    "with POLYGONS_GEOJSON_PATH.open('w', encoding='utf-8') as f:\n",
    "    json.dump(geojson, f, indent=2)\n",
    "\n",
    "print(f'Saved: {POLYGONS_JSON_PATH}')\n",
    "print(f'Saved: {POLYGONS_GEOJSON_PATH}')\n",
    "print(f'\\nExample polygon output:')\n",
    "if json_polygons:\n",
    "    print(json.dumps(json_polygons[0], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}