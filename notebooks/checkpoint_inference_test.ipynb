{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d0250f",
   "metadata": {},
   "source": [
    "# DeepRoof Checkpoint Inference Notebook (Production-Aligned)\n",
    "\n",
    "Этот ноутбук запускает тот же inference-пайплайн, что и CLI (`tools/inference.py`),\n",
    "чтобы результаты в ноутбуке и проде совпадали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a0e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def detect_project_root() -> Path:\n",
    "    c = Path.cwd().resolve()\n",
    "    for cand in [c, *c.parents]:\n",
    "        if (cand / 'configs').exists() and (cand / 'deeproof').exists():\n",
    "            return cand\n",
    "    raise FileNotFoundError('Could not auto-detect project root')\n",
    "\n",
    "PROJECT_ROOT = detect_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print('PROJECT_ROOT =', PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8867d9",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6234a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG_PATH = PROJECT_ROOT / 'configs' / 'deeproof_production_swin_L.py'\n",
    "CONFIG_PATH = DEFAULT_CONFIG_PATH\n",
    "\n",
    "\n",
    "def _pick_latest_work_dir() -> Path:\n",
    "    roots = [Path('/workspace/roof/work_dirs'), PROJECT_ROOT / 'work_dirs']\n",
    "    candidates = []\n",
    "    for root in roots:\n",
    "        if root.exists():\n",
    "            candidates.extend([p for p in root.glob('deeproof_notebook_*') if p.is_dir()])\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        return candidates[0]\n",
    "    return PROJECT_ROOT / 'work_dirs' / 'deeproof_notebook_20260223_085737'\n",
    "\n",
    "\n",
    "# Requested run directory/checkpoint\n",
    "WORK_DIR = Path('/workspace/roof/work_dirs/deeproof_notebook_20260223_085737')\n",
    "if not WORK_DIR.exists():\n",
    "    WORK_DIR = _pick_latest_work_dir()\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs' / 'checkpoint_inference'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Input image\n",
    "INPUT_IMAGE_PATH = PROJECT_ROOT / 'test.png'\n",
    "\n",
    "# Optional multi-candidate file (.txt/.json)\n",
    "INPUT_CANDIDATES_FILE = ''\n",
    "CANDIDATE_SELECTION = 'best'   # best|weighted\n",
    "\n",
    "# Segmentation-first profile (quality > speed)\n",
    "MIN_CONF = 0.30\n",
    "MIN_CONF_FLAT = 0.30\n",
    "MIN_CONF_SLOPED = 0.40\n",
    "MIN_AREA_PX = 120\n",
    "MIN_MASK_DENSITY = 0.02\n",
    "MAX_INSTANCES = 120\n",
    "TTA_MODE = 'full'  # full|lite|none\n",
    "DISABLE_AMP = False\n",
    "OOM_RETRY_NO_TTA = True\n",
    "OOM_FALLBACK_CPU = True\n",
    "\n",
    "# Tiling (large tiles + overlap to reduce seams)\n",
    "TILE_SIZE = 1408\n",
    "STRIDE = 1024\n",
    "\n",
    "# Visualization (2D only, no mask wash)\n",
    "VIZ_FILL_ALPHA = 0.0\n",
    "KEEP_BACKGROUND = False\n",
    "ALLOW_SEMANTIC_FALLBACK = False\n",
    "\n",
    "# Advanced options (disabled for pure segmentation quality)\n",
    "ENABLE_SR = False\n",
    "SR_SCALE = 2.0\n",
    "ENABLE_GRAPH = False\n",
    "ENABLE_GRAPH_SNAP = False\n",
    "USE_MODEL_EDGE_FOR_GRAPH = False\n",
    "ENABLE_SAM2 = False\n",
    "SAM2_MODEL_TYPE = 'vit_b'\n",
    "SAM2_CHECKPOINT = ''\n",
    "DEPTH_MAP = ''\n",
    "\n",
    "# Explicit checkpoint preference\n",
    "CHECKPOINT_NAME = 'iter_500.pth'\n",
    "CHECKPOINT_OVERRIDE = WORK_DIR / CHECKPOINT_NAME\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def _inspect_checkpoint(path: Path):\n",
    "    required = ('dense_geometry_head.', 'edge_head.')\n",
    "    try:\n",
    "        try:\n",
    "            obj = torch.load(str(path), map_location='cpu', weights_only=False)\n",
    "        except TypeError:\n",
    "            obj = torch.load(str(path), map_location='cpu')\n",
    "    except Exception:\n",
    "        return False, None\n",
    "\n",
    "    state = obj.get('state_dict', obj) if isinstance(obj, dict) else {}\n",
    "    compatible = False\n",
    "    if isinstance(state, dict):\n",
    "        keys = tuple(state.keys())\n",
    "        compatible = all(any(k.startswith(pref) for k in keys) for pref in required)\n",
    "\n",
    "    cfg_text = None\n",
    "    if isinstance(obj, dict):\n",
    "        meta = obj.get('meta', {})\n",
    "        if isinstance(meta, dict):\n",
    "            for key in ('config', 'cfg', 'pretty_text'):\n",
    "                val = meta.get(key)\n",
    "                if isinstance(val, str) and 'model' in val:\n",
    "                    cfg_text = val\n",
    "                    break\n",
    "    return compatible, cfg_text\n",
    "\n",
    "\n",
    "# Resolve requested checkpoint robustly.\n",
    "requested = [\n",
    "    CHECKPOINT_OVERRIDE,\n",
    "    WORK_DIR / 'iter_60000.pth',\n",
    "    WORK_DIR / 'iter_060000.pth',\n",
    "]\n",
    "requested += sorted(WORK_DIR.glob('iter_500*.pth'), reverse=True)\n",
    "requested += sorted(WORK_DIR.glob('iter_*60*.pth'), reverse=True)\n",
    "requested += sorted(WORK_DIR.glob('iter_*.pth'), reverse=True)\n",
    "\n",
    "seen = set()\n",
    "requested_unique = []\n",
    "for p in requested:\n",
    "    sp = str(p)\n",
    "    if sp not in seen:\n",
    "        seen.add(sp)\n",
    "        requested_unique.append(p)\n",
    "\n",
    "existing = [p for p in requested_unique if p.exists()]\n",
    "if not existing:\n",
    "    available = sorted(WORK_DIR.glob('*.pth')) if WORK_DIR.exists() else []\n",
    "    err_lines = ['Requested checkpoint not found. Tried:']\n",
    "    err_lines.extend([f'- {p}' for p in requested_unique])\n",
    "    if available:\n",
    "        err_lines.append('Available in WORK_DIR:')\n",
    "        err_lines.extend([f'- {p}' for p in available])\n",
    "    else:\n",
    "        err_lines.append('No .pth files found in WORK_DIR.')\n",
    "    raise FileNotFoundError(chr(10).join(err_lines))\n",
    "\n",
    "CHECKPOINT_PATH = existing[0]\n",
    "CHECKPOINT_COMPATIBLE, CKPT_CONFIG_TEXT = _inspect_checkpoint(CHECKPOINT_PATH)\n",
    "\n",
    "# Use architecture-matching config embedded in checkpoint metadata when available.\n",
    "if CKPT_CONFIG_TEXT:\n",
    "    ckpt_cfg_path = OUTPUT_DIR / f'config_from_{CHECKPOINT_PATH.stem}.py'\n",
    "    ckpt_cfg_path.write_text(CKPT_CONFIG_TEXT)\n",
    "    CONFIG_PATH = ckpt_cfg_path\n",
    "else:\n",
    "    # Fallback: try config snapshot dumped in work_dir by mmengine.\n",
    "    dumped_cfgs = sorted(\n",
    "        [p for p in WORK_DIR.glob('*.py') if p.name.startswith('deeproof_')],\n",
    "        key=lambda p: p.stat().st_mtime,\n",
    "        reverse=True,\n",
    "    )\n",
    "    if dumped_cfgs:\n",
    "        CONFIG_PATH = dumped_cfgs[0]\n",
    "\n",
    "if not CHECKPOINT_COMPATIBLE:\n",
    "    print('WARNING: checkpoint is not fully compatible (dense_geometry_head/edge_head missing). Inference will still run in segmentation-first mode.')\n",
    "\n",
    "if not INPUT_IMAGE_PATH.exists():\n",
    "    raise FileNotFoundError(f'Input image not found: {INPUT_IMAGE_PATH}')\n",
    "\n",
    "print('CONFIG:', CONFIG_PATH)\n",
    "print('CONFIG_SOURCE:', 'checkpoint_meta' if CKPT_CONFIG_TEXT else ('work_dir_dump' if CONFIG_PATH != DEFAULT_CONFIG_PATH else 'default'))\n",
    "print('WORK_DIR:', WORK_DIR)\n",
    "print('CHECKPOINT:', CHECKPOINT_PATH)\n",
    "print('CHECKPOINT_COMPATIBLE:', CHECKPOINT_COMPATIBLE)\n",
    "print('INPUT:', INPUT_IMAGE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc627d9c",
   "metadata": {},
   "source": [
    "## Run Production Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_geojson = OUTPUT_DIR / 'result.geojson'\n",
    "cmd = [\n",
    "    sys.executable, str(PROJECT_ROOT / 'tools' / 'inference.py'),\n",
    "    '--config', str(CONFIG_PATH),\n",
    "    '--checkpoint', str(CHECKPOINT_PATH),\n",
    "    '--input', str(INPUT_IMAGE_PATH),\n",
    "    '--output', str(output_geojson),\n",
    "    '--tile-size', str(TILE_SIZE),\n",
    "    '--stride', str(STRIDE),\n",
    "    '--min_confidence', str(MIN_CONF),\n",
    "    '--min_confidence_flat', str(MIN_CONF_FLAT),\n",
    "    '--min_confidence_sloped', str(MIN_CONF_SLOPED),\n",
    "    '--min_area_px', str(MIN_AREA_PX),\n",
    "    '--min_mask_density', str(MIN_MASK_DENSITY),\n",
    "    '--max_instances', str(MAX_INSTANCES),\n",
    "    '--tta-mode', str(TTA_MODE),\n",
    "    '--viz-fill-alpha', str(VIZ_FILL_ALPHA),\n",
    "    '--save_viz',\n",
    "    '--save_metadata',\n",
    "]\n",
    "\n",
    "if KEEP_BACKGROUND:\n",
    "    cmd += ['--keep-background']\n",
    "if ALLOW_SEMANTIC_FALLBACK:\n",
    "    cmd += ['--allow-semantic-fallback']\n",
    "if INPUT_CANDIDATES_FILE:\n",
    "    cmd += ['--input-candidates', str(INPUT_CANDIDATES_FILE), '--candidate-selection', CANDIDATE_SELECTION]\n",
    "if ENABLE_SR:\n",
    "    cmd += ['--sr-enable', '--sr-scale', str(SR_SCALE), '--sr-backend', 'bicubic', '--sr-fuse-mode', 'weighted']\n",
    "if ENABLE_GRAPH:\n",
    "    cmd += ['--graph-enable']\n",
    "if ENABLE_GRAPH_SNAP:\n",
    "    cmd += ['--polygon-snap-to-graph']\n",
    "if USE_MODEL_EDGE_FOR_GRAPH:\n",
    "    cmd += ['--graph-use-model-edge']\n",
    "if ENABLE_SAM2 and SAM2_CHECKPOINT:\n",
    "    cmd += ['--sam2-enable', '--sam2-model-type', str(SAM2_MODEL_TYPE), '--sam2-checkpoint', str(SAM2_CHECKPOINT)]\n",
    "if DEPTH_MAP:\n",
    "    cmd += ['--depth-map', str(DEPTH_MAP)]\n",
    "\n",
    "# These flags must be appended BEFORE process start.\n",
    "if DISABLE_AMP:\n",
    "    cmd += ['--disable-amp']\n",
    "if OOM_RETRY_NO_TTA:\n",
    "    cmd += ['--oom-retry-no-tta']\n",
    "if OOM_FALLBACK_CPU:\n",
    "    cmd += ['--oom-fallback-cpu']\n",
    "\n",
    "print('Running command:', ' '.join(cmd))\n",
    "run_env = os.environ.copy()\n",
    "run_env.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\n",
    "subprocess.check_call(cmd, cwd=str(PROJECT_ROOT), env=run_env)\n",
    "print('Done:', output_geojson)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4e821",
   "metadata": {},
   "source": [
    "## Quick Results Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_geojson = OUTPUT_DIR / 'result.geojson'\n",
    "result_overlay = OUTPUT_DIR / 'result.png'\n",
    "result_meta = OUTPUT_DIR / 'result.meta.json'\n",
    "\n",
    "if result_geojson.exists():\n",
    "    data = json.loads(result_geojson.read_text(encoding='utf-8'))\n",
    "    feats = data.get('features', [])\n",
    "    print('features:', len(feats))\n",
    "    if feats:\n",
    "        classes = {}\n",
    "        for f in feats:\n",
    "            name = f.get('properties', {}).get('class_name', 'unknown')\n",
    "            classes[name] = classes.get(name, 0) + 1\n",
    "        print('class counts:', classes)\n",
    "        props = feats[0].get('properties', {})\n",
    "        print('sample properties keys:', sorted(props.keys()))\n",
    "\n",
    "if result_meta.exists():\n",
    "    meta = json.loads(result_meta.read_text(encoding='utf-8'))\n",
    "    print('runtime versions:', meta.get('runtime_versions', {}))\n",
    "\n",
    "if result_overlay.exists():\n",
    "    img = cv2.cvtColor(cv2.imread(str(result_overlay)), cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img)\n",
    "    plt.title('Segmentation Overlay (2D)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}