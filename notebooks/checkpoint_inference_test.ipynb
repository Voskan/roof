{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6980e0e6",
   "metadata": {},
   "source": [
    "# DeepRoof Checkpoint Inference (PNG/JPG)\n",
    "\n",
    "Notebook validates the checkpoint, loads the DeepRoof model, runs segmentation on one image, and saves visual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_project_root() -> Path:\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        Path.cwd().parent,\n",
    "        Path('/workspace/roof'),\n",
    "        Path('/Users/voskan/Desktop/DeepRoof-2026'),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if (c / 'configs').exists() and (c / 'deeproof').exists():\n",
    "            return c\n",
    "    raise FileNotFoundError('Could not auto-detect project root with configs/ and deeproof/.')\n",
    "\n",
    "\n",
    "def resolve_checkpoint(work_dir: Path, fallback_ckpt: Path) -> Path:\n",
    "    \"\"\"Prefer last_checkpoint pointer to avoid accidentally using stale weights.\"\"\"\n",
    "    last_ckpt_ptr = work_dir / 'last_checkpoint'\n",
    "    if last_ckpt_ptr.exists():\n",
    "        target = last_ckpt_ptr.read_text(encoding='utf-8').strip()\n",
    "        if target:\n",
    "            t = Path(target)\n",
    "            if not t.is_absolute():\n",
    "                t = work_dir / t\n",
    "            if t.exists():\n",
    "                return t\n",
    "\n",
    "    if fallback_ckpt.exists():\n",
    "        return fallback_ckpt\n",
    "\n",
    "    return fallback_ckpt\n",
    "\n",
    "\n",
    "PROJECT_ROOT = detect_project_root()\n",
    "CONFIG_PATH = PROJECT_ROOT / 'configs' / 'deeproof_scratch_swin_L.py'\n",
    "\n",
    "# Set training run directory here. Notebook will auto-pick `last_checkpoint` if present.\n",
    "WORK_DIR = PROJECT_ROOT / 'work_dirs' / 'swin_l_scratch_v1'\n",
    "SERVER_CHECKPOINT_PATH = WORK_DIR / 'iter_8000.pth'\n",
    "LOCAL_ANALYSIS_CHECKPOINT_PATH = Path('/Users/voskan/Downloads/iter_8000.pth')\n",
    "CHECKPOINT_PATH = resolve_checkpoint(WORK_DIR, SERVER_CHECKPOINT_PATH)\n",
    "if not CHECKPOINT_PATH.exists() and LOCAL_ANALYSIS_CHECKPOINT_PATH.exists():\n",
    "    CHECKPOINT_PATH = LOCAL_ANALYSIS_CHECKPOINT_PATH\n",
    "\n",
    "# Set your test image here (PNG/JPG/TIF).\n",
    "INPUT_IMAGE_PATH = Path('/workspace/test.png')\n",
    "if not INPUT_IMAGE_PATH.exists():\n",
    "    fallback = PROJECT_ROOT / 'test.png'\n",
    "    if fallback.exists():\n",
    "        INPUT_IMAGE_PATH = fallback\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs' / 'checkpoint_inference'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OVERLAY_PATH = OUTPUT_DIR / 'test_segmentation_overlay.png'\n",
    "SEM_MASK_PATH = OUTPUT_DIR / 'test_semantic_mask.png'\n",
    "SUMMARY_PATH = OUTPUT_DIR / 'test_inference_summary.json'\n",
    "POLYGONS_JSON_PATH = OUTPUT_DIR / 'test_roof_polygons.json'\n",
    "POLYGONS_GEOJSON_PATH = OUTPUT_DIR / 'test_roof_polygons.geojson'\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'PROJECT_ROOT: {PROJECT_ROOT}')\n",
    "print(f'CONFIG: {CONFIG_PATH}')\n",
    "print(f'WORK_DIR: {WORK_DIR}')\n",
    "print(f'CHECKPOINT: {CHECKPOINT_PATH}')\n",
    "if CHECKPOINT_PATH.exists():\n",
    "    print(f'CHECKPOINT mtime: {CHECKPOINT_PATH.stat().st_mtime}')\n",
    "print(f'INPUT: {INPUT_IMAGE_PATH}')\n",
    "print(f'POLYGONS JSON: {POLYGONS_JSON_PATH}')\n",
    "print(f'DEVICE: {DEVICE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47795d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in (CONFIG_PATH, CHECKPOINT_PATH, INPUT_IMAGE_PATH):\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f'Path not found: {p}')\n",
    "\n",
    "img_bgr = cv2.imread(str(INPUT_IMAGE_PATH), cv2.IMREAD_COLOR)\n",
    "if img_bgr is None:\n",
    "    raise RuntimeError(f'Could not load image: {INPUT_IMAGE_PATH}')\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "H, W = img_rgb.shape[:2]\n",
    "print(f'Loaded image: {W}x{H}')\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint compatibility inspection\n",
    "# Required for PyTorch>=2.6 when old MMEngine checkpoints contain non-tensor objects.\n",
    "os.environ.setdefault('TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD', '1')\n",
    "\n",
    "def inspect_checkpoint(path: Path):\n",
    "    try:\n",
    "        ckpt = torch.load(str(path), map_location='cpu', weights_only=False)\n",
    "    except TypeError:\n",
    "        # Older torch versions without weights_only argument\n",
    "        ckpt = torch.load(str(path), map_location='cpu')\n",
    "\n",
    "    if not isinstance(ckpt, dict):\n",
    "        return {'type': str(type(ckpt)), 'error': 'checkpoint is not a dict'}\n",
    "\n",
    "    state_dict = ckpt.get('state_dict', ckpt.get('model', None))\n",
    "    info = {\n",
    "        'top_keys': list(ckpt.keys()),\n",
    "        'has_state_dict': isinstance(state_dict, dict),\n",
    "        'meta_keys': list(ckpt.get('meta', {}).keys()) if isinstance(ckpt.get('meta', None), dict) else [],\n",
    "    }\n",
    "\n",
    "    if isinstance(state_dict, dict):\n",
    "        keys = list(state_dict.keys())\n",
    "        info['num_params'] = len(keys)\n",
    "        info['first_keys'] = keys[:15]\n",
    "        probes = [\n",
    "            'backbone.patch_embed.projection.weight',\n",
    "            'decode_head.query_embed.weight',\n",
    "            'geometry_head.layers.0.weight',\n",
    "            'module.backbone.patch_embed.projection.weight',\n",
    "        ]\n",
    "        info['probe_hits'] = {k: (k in state_dict) for k in probes}\n",
    "\n",
    "    return info\n",
    "\n",
    "ckpt_info = inspect_checkpoint(CHECKPOINT_PATH)\n",
    "print(json.dumps(ckpt_info, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from mmseg.utils import register_all_modules\n",
    "from mmseg.apis import init_model, inference_model\n",
    "from mmengine.config import ConfigDict\n",
    "\n",
    "register_all_modules(init_default_scope=False)\n",
    "\n",
    "# Ensure custom modules are imported and registered.\n",
    "import deeproof.models.backbones.swin_v2_compat\n",
    "import deeproof.models.deeproof_model\n",
    "import deeproof.models.heads.mask2former_head\n",
    "import deeproof.models.heads.geometry_head\n",
    "import deeproof.models.losses\n",
    "\n",
    "def _ensure_test_pipeline(cfg):\n",
    "    if hasattr(cfg, 'test_pipeline') and cfg.test_pipeline:\n",
    "        return\n",
    "\n",
    "    pipeline = None\n",
    "    for loader_key in ('test_dataloader', 'val_dataloader', 'train_dataloader'):\n",
    "        if loader_key in cfg and cfg.get(loader_key) is not None:\n",
    "            dataset_cfg = cfg[loader_key].get('dataset', None)\n",
    "            if dataset_cfg is not None:\n",
    "                candidate = dataset_cfg.get('pipeline', None)\n",
    "                if candidate:\n",
    "                    pipeline = list(candidate)\n",
    "                    break\n",
    "\n",
    "    if not pipeline:\n",
    "        pipeline = [dict(type='LoadImageFromFile'), dict(type='PackSegInputs')]\n",
    "\n",
    "    filtered = []\n",
    "    has_load_image = False\n",
    "    has_pack_inputs = False\n",
    "    for transform in pipeline:\n",
    "        if not isinstance(transform, dict):\n",
    "            continue\n",
    "        t = transform.get('type', '')\n",
    "        if t == 'LoadAnnotations':\n",
    "            continue\n",
    "        if t == 'LoadImageFromFile':\n",
    "            has_load_image = True\n",
    "        if t == 'PackSegInputs':\n",
    "            has_pack_inputs = True\n",
    "        filtered.append(transform)\n",
    "\n",
    "    if not has_load_image:\n",
    "        filtered.insert(0, dict(type='LoadImageFromFile'))\n",
    "    if not has_pack_inputs:\n",
    "        filtered.append(dict(type='PackSegInputs'))\n",
    "\n",
    "    cfg.test_pipeline = filtered\n",
    "\n",
    "model = init_model(str(CONFIG_PATH), str(CHECKPOINT_PATH), device=DEVICE)\n",
    "_ensure_test_pipeline(model.cfg)\n",
    "\n",
    "# Prefer slide inference for large images to reduce quality drop on unseen resolutions.\n",
    "def _normalize_test_cfg(test_cfg):\n",
    "    default_slide = dict(mode='slide', crop_size=(1024, 1024), stride=(768, 768))\n",
    "    if test_cfg is None:\n",
    "        return ConfigDict(default_slide)\n",
    "    if isinstance(test_cfg, dict):\n",
    "        merged = dict(default_slide)\n",
    "        merged.update(test_cfg)\n",
    "        merged.setdefault('mode', 'slide')\n",
    "        return ConfigDict(merged)\n",
    "\n",
    "    # Attr-based configs\n",
    "    if not hasattr(test_cfg, 'mode'):\n",
    "        try:\n",
    "            setattr(test_cfg, 'mode', 'slide')\n",
    "        except Exception:\n",
    "            return ConfigDict(default_slide)\n",
    "    if getattr(test_cfg, 'mode', None) == 'slide':\n",
    "        if getattr(test_cfg, 'crop_size', None) is None:\n",
    "            setattr(test_cfg, 'crop_size', (1024, 1024))\n",
    "        if getattr(test_cfg, 'stride', None) is None:\n",
    "            setattr(test_cfg, 'stride', (768, 768))\n",
    "    return test_cfg\n",
    "\n",
    "model.test_cfg = _normalize_test_cfg(getattr(model, 'test_cfg', None))\n",
    "\n",
    "model.eval()\n",
    "print('Model loaded successfully.')\n",
    "print('test_pipeline:', model.cfg.test_pipeline)\n",
    "print('model.test_cfg:', model.test_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_model(model, str(INPUT_IMAGE_PATH))\n",
    "if isinstance(result, (list, tuple)):\n",
    "    result = result[0]\n",
    "\n",
    "# Semantic map\n",
    "if hasattr(result, 'pred_sem_seg') and hasattr(result.pred_sem_seg, 'data'):\n",
    "    sem_map = result.pred_sem_seg.data.squeeze(0).detach().cpu().numpy().astype(np.uint8)\n",
    "else:\n",
    "    sem_map = np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "if sem_map.shape != (H, W):\n",
    "    sem_map = cv2.resize(sem_map, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Instances (if available)\n",
    "masks = np.zeros((0, H, W), dtype=bool)\n",
    "scores = np.array([], dtype=np.float32)\n",
    "labels = np.array([], dtype=np.int64)\n",
    "instance_source = 'none'\n",
    "\n",
    "if hasattr(result, 'pred_instances') and result.pred_instances is not None:\n",
    "    inst = result.pred_instances\n",
    "    if hasattr(inst, 'masks') and inst.masks is not None:\n",
    "        masks_t = inst.masks\n",
    "        if torch.is_tensor(masks_t):\n",
    "            masks_np = masks_t.detach().cpu().numpy().astype(bool)\n",
    "            if masks_np.ndim == 3:\n",
    "                resized_masks = []\n",
    "                for m in masks_np:\n",
    "                    if m.shape != (H, W):\n",
    "                        m = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                    resized_masks.append(m)\n",
    "                masks = np.stack(resized_masks, axis=0) if resized_masks else np.zeros((0, H, W), dtype=bool)\n",
    "\n",
    "    if hasattr(inst, 'scores') and inst.scores is not None:\n",
    "        scores = inst.scores.detach().cpu().numpy()\n",
    "    if hasattr(inst, 'labels') and inst.labels is not None:\n",
    "        labels = inst.labels.detach().cpu().numpy()\n",
    "\n",
    "    if len(masks) > 0:\n",
    "        instance_source = 'model_pred_instances'\n",
    "\n",
    "# Fallback: build pseudo-instances from semantic components when model returns semantic-only output.\n",
    "if len(masks) == 0:\n",
    "    comp_masks = []\n",
    "    comp_labels = []\n",
    "    min_area = 64\n",
    "    for cls_id in np.unique(sem_map):\n",
    "        cls_id = int(cls_id)\n",
    "        if cls_id <= 0 or cls_id == 255:\n",
    "            continue\n",
    "        binary = (sem_map == cls_id).astype(np.uint8)\n",
    "        num_comp, comp = cv2.connectedComponents(binary, connectivity=8)\n",
    "        for comp_id in range(1, int(num_comp)):\n",
    "            m = (comp == comp_id)\n",
    "            if int(m.sum()) < min_area:\n",
    "                continue\n",
    "            comp_masks.append(m)\n",
    "            comp_labels.append(cls_id)\n",
    "\n",
    "    if comp_masks:\n",
    "        masks = np.stack(comp_masks, axis=0).astype(bool)\n",
    "        labels = np.array(comp_labels, dtype=np.int64)\n",
    "        # Do not fabricate confidence values in fallback mode.\n",
    "        scores = np.array([], dtype=np.float32)\n",
    "        instance_source = 'semantic_connected_components_fallback'\n",
    "\n",
    "roof_ratio = float((sem_map > 0).sum()) / float(sem_map.size)\n",
    "print(f'Unique semantic classes: {np.unique(sem_map).tolist()}')\n",
    "print(f'Roof pixel ratio: {roof_ratio:.4f}')\n",
    "print(f'Predicted instances: {len(masks)} (source={instance_source})')\n",
    "if len(scores) > 0:\n",
    "    print(f'Score range: {float(scores.min()):.4f} .. {float(scores.max()):.4f}')\n",
    "if roof_ratio > 0.90:\n",
    "    print('WARNING: segmentation marks >90% pixels as roof. This usually indicates poor generalization or preprocessing mismatch.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a2c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palette: background, flat_roof, sloped_roof\n",
    "palette = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 255, 0],\n",
    "    [255, 0, 0],\n",
    "], dtype=np.uint8)\n",
    "\n",
    "if hasattr(model, 'dataset_meta') and isinstance(model.dataset_meta, dict):\n",
    "    model_palette = model.dataset_meta.get('palette', None)\n",
    "    if model_palette is not None and len(model_palette) >= 3:\n",
    "        palette = np.array(model_palette, dtype=np.uint8)\n",
    "\n",
    "sem_vis = palette[np.clip(sem_map, 0, len(palette) - 1)]\n",
    "overlay = cv2.addWeighted(img_rgb, 0.60, sem_vis, 0.40, 0.0)\n",
    "\n",
    "# --- Polygon extraction from instance masks ---\n",
    "roof_polygons = []\n",
    "MIN_SCORE = 0.25\n",
    "MIN_POLY_AREA = 64\n",
    "\n",
    "for i, mask in enumerate(masks):\n",
    "    if i < len(scores) and float(scores[i]) < MIN_SCORE:\n",
    "        continue\n",
    "\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        area = float(cv2.contourArea(contour))\n",
    "        if area < MIN_POLY_AREA:\n",
    "            continue\n",
    "\n",
    "        epsilon = 0.003 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        poly = approx.reshape(-1, 2)\n",
    "        if poly.shape[0] < 3:\n",
    "            continue\n",
    "\n",
    "        cls_id = int(labels[i]) if i < len(labels) else 1\n",
    "        score = float(scores[i]) if i < len(scores) else None\n",
    "\n",
    "        roof_polygons.append({\n",
    "            'polygon_id': len(roof_polygons),\n",
    "            'class_id': cls_id,\n",
    "            'score': score,\n",
    "            'area_px': area,\n",
    "            'points_xy': poly.astype(int).tolist(),\n",
    "        })\n",
    "\n",
    "# Draw polygons\n",
    "for poly_obj in roof_polygons:\n",
    "    pts = np.array(poly_obj['points_xy'], dtype=np.int32).reshape(-1, 1, 2)\n",
    "    cv2.polylines(overlay, [pts], True, (255, 255, 255), 2)\n",
    "\n",
    "    # label near polygon centroid\n",
    "    m = cv2.moments(pts)\n",
    "    if m['m00'] > 0:\n",
    "        cx = int(m['m10'] / m['m00'])\n",
    "        cy = int(m['m01'] / m['m00'])\n",
    "    else:\n",
    "        cx, cy = pts[0, 0, 0], pts[0, 0, 1]\n",
    "\n",
    "    txt = f\"id:{poly_obj['polygon_id']} cls:{poly_obj['class_id']}\"\n",
    "    if poly_obj['score'] is not None:\n",
    "        txt += f\" {poly_obj['score']:.2f}\"\n",
    "    cv2.putText(overlay, txt, (cx, max(0, cy - 4)), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "# Save masks/overlay\n",
    "cv2.imwrite(str(OVERLAY_PATH), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite(str(SEM_MASK_PATH), sem_map)\n",
    "\n",
    "# Save polygons JSON\n",
    "with POLYGONS_JSON_PATH.open('w', encoding='utf-8') as f:\n",
    "    json.dump({'image': str(INPUT_IMAGE_PATH), 'polygons': roof_polygons}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Save simple GeoJSON-like pixel-space output\n",
    "geojson = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': []\n",
    "}\n",
    "for poly_obj in roof_polygons:\n",
    "    coords = [[float(x), float(y)] for x, y in poly_obj['points_xy']]\n",
    "    # close ring\n",
    "    if coords and coords[0] != coords[-1]:\n",
    "        coords.append(coords[0])\n",
    "    geojson['features'].append({\n",
    "        'type': 'Feature',\n",
    "        'properties': {\n",
    "            'polygon_id': poly_obj['polygon_id'],\n",
    "            'class_id': poly_obj['class_id'],\n",
    "            'score': poly_obj['score'],\n",
    "            'area_px': poly_obj['area_px'],\n",
    "        },\n",
    "        'geometry': {\n",
    "            'type': 'Polygon',\n",
    "            'coordinates': [coords],\n",
    "        },\n",
    "    })\n",
    "\n",
    "with POLYGONS_GEOJSON_PATH.open('w', encoding='utf-8') as f:\n",
    "    json.dump(geojson, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Input')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(sem_vis)\n",
    "plt.title('Semantic map')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(overlay)\n",
    "plt.title(f'Roof polygons: {len(roof_polygons)}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f'Saved overlay: {OVERLAY_PATH}')\n",
    "print(f'Saved semantic mask: {SEM_MASK_PATH}')\n",
    "print(f'Saved polygons JSON: {POLYGONS_JSON_PATH}')\n",
    "print(f'Saved polygons GeoJSON: {POLYGONS_GEOJSON_PATH}')\n",
    "print(f'Extracted polygons: {len(roof_polygons)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccece88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'project_root': str(PROJECT_ROOT),\n",
    "    'work_dir': str(WORK_DIR),\n",
    "    'input_image': str(INPUT_IMAGE_PATH),\n",
    "    'config': str(CONFIG_PATH),\n",
    "    'checkpoint': str(CHECKPOINT_PATH),\n",
    "    'device': DEVICE,\n",
    "    'image_size': [int(H), int(W)],\n",
    "    'semantic_classes': [int(x) for x in np.unique(sem_map)],\n",
    "    'roof_pixel_ratio': float((sem_map > 0).sum()) / float(sem_map.size),\n",
    "    'instance_count': int(len(masks)),\n",
    "    'instance_source': instance_source,\n",
    "    'polygon_count': int(len(roof_polygons)),\n",
    "    'score_mean': float(scores.mean()) if len(scores) > 0 else None,\n",
    "    'score_max': float(scores.max()) if len(scores) > 0 else None,\n",
    "    'overlay_path': str(OVERLAY_PATH),\n",
    "    'semantic_mask_path': str(SEM_MASK_PATH),\n",
    "    'polygons_json_path': str(POLYGONS_JSON_PATH),\n",
    "    'polygons_geojson_path': str(POLYGONS_GEOJSON_PATH),\n",
    "}\n",
    "\n",
    "with SUMMARY_PATH.open('w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
    "print(f'Saved summary: {SUMMARY_PATH}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}