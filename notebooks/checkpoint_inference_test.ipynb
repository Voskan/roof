{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3ef3388",
      "metadata": {},
      "source": [
        "# DeepRoof Checkpoint Inference on One PNG\n",
        "\n",
        "This notebook runs model inference on one image (`/workspace/test.png`) using a checkpoint and shows segmentation results visually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6108d044",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "748ce2d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ROOT = Path('/workspace/roof')\n",
        "CONFIG_PATH = PROJECT_ROOT / 'configs' / 'deeproof_scratch_swin_L.py'\n",
        "CHECKPOINT_PATH = PROJECT_ROOT / 'work_dirs' / 'swin_l_scratch_v1' / 'iter_8000.pth'\n",
        "INPUT_IMAGE_PATH = Path('/workspace/test.png')\n",
        "\n",
        "OUTPUT_DIR = PROJECT_ROOT / 'outputs' / 'checkpoint_inference'\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OVERLAY_PATH = OUTPUT_DIR / 'test_segmentation_overlay.png'\n",
        "SEM_MASK_PATH = OUTPUT_DIR / 'test_semantic_mask.png'\n",
        "SUMMARY_PATH = OUTPUT_DIR / 'test_inference_summary.json'\n",
        "\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f'CONFIG: {CONFIG_PATH}')\n",
        "print(f'CHECKPOINT: {CHECKPOINT_PATH}')\n",
        "print(f'INPUT: {INPUT_IMAGE_PATH}')\n",
        "print(f'DEVICE: {DEVICE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b558d52d",
      "metadata": {},
      "outputs": [],
      "source": [
        "for p in (CONFIG_PATH, CHECKPOINT_PATH, INPUT_IMAGE_PATH):\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f'Path not found: {p}')\n",
        "\n",
        "img_bgr = cv2.imread(str(INPUT_IMAGE_PATH), cv2.IMREAD_COLOR)\n",
        "if img_bgr is None:\n",
        "    raise RuntimeError(f'Could not load image: {INPUT_IMAGE_PATH}')\n",
        "\n",
        "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "H, W = img_rgb.shape[:2]\n",
        "print(f'Loaded image: {W}x{H}')\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(img_rgb)\n",
        "plt.title('Input image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4cb971",
      "metadata": {},
      "outputs": [],
      "source": [
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from mmseg.utils import register_all_modules\n",
        "from mmseg.apis import init_model, inference_model\n",
        "\n",
        "register_all_modules(init_default_scope=False)\n",
        "\n",
        "# Ensure custom modules are imported and registered.\n",
        "import deeproof.models.backbones.swin_v2_compat\n",
        "import deeproof.models.deeproof_model\n",
        "import deeproof.models.heads.mask2former_head\n",
        "import deeproof.models.heads.geometry_head\n",
        "import deeproof.models.losses\n",
        "\n",
        "model = init_model(str(CONFIG_PATH), str(CHECKPOINT_PATH), device=DEVICE)\n",
        "model.eval()\n",
        "print('Model loaded successfully.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6bb9fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "result = inference_model(model, str(INPUT_IMAGE_PATH))\n",
        "if isinstance(result, (list, tuple)):\n",
        "    result = result[0]\n",
        "\n",
        "# Semantic map\n",
        "if hasattr(result, 'pred_sem_seg') and hasattr(result.pred_sem_seg, 'data'):\n",
        "    sem_map = result.pred_sem_seg.data.squeeze(0).detach().cpu().numpy().astype(np.uint8)\n",
        "else:\n",
        "    sem_map = np.zeros((H, W), dtype=np.uint8)\n",
        "\n",
        "if sem_map.shape != (H, W):\n",
        "    sem_map = cv2.resize(sem_map, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "# Instances (if available)\n",
        "masks = np.zeros((0, H, W), dtype=bool)\n",
        "scores = np.array([], dtype=np.float32)\n",
        "labels = np.array([], dtype=np.int64)\n",
        "if hasattr(result, 'pred_instances') and result.pred_instances is not None:\n",
        "    inst = result.pred_instances\n",
        "    if hasattr(inst, 'masks') and inst.masks is not None:\n",
        "        masks_t = inst.masks\n",
        "        if torch.is_tensor(masks_t):\n",
        "            masks = masks_t.detach().cpu().numpy().astype(bool)\n",
        "    if hasattr(inst, 'scores') and inst.scores is not None:\n",
        "        scores = inst.scores.detach().cpu().numpy()\n",
        "    if hasattr(inst, 'labels') and inst.labels is not None:\n",
        "        labels = inst.labels.detach().cpu().numpy()\n",
        "\n",
        "print(f'Unique semantic classes: {np.unique(sem_map).tolist()}')\n",
        "print(f'Predicted instances: {len(masks)}')\n",
        "if len(scores) > 0:\n",
        "    print(f'Score range: {float(scores.min()):.4f} .. {float(scores.max()):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ccf5e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Palette: background, flat_roof, sloped_roof\n",
        "palette = np.array([\n",
        "    [0, 0, 0],\n",
        "    [0, 255, 0],\n",
        "    [255, 0, 0],\n",
        "], dtype=np.uint8)\n",
        "\n",
        "sem_vis = palette[np.clip(sem_map, 0, len(palette) - 1)]\n",
        "overlay = cv2.addWeighted(img_rgb, 0.60, sem_vis, 0.40, 0.0)\n",
        "\n",
        "# Draw instance contours and scores if present\n",
        "for i, mask in enumerate(masks):\n",
        "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(overlay, contours, -1, (255, 255, 255), 1)\n",
        "\n",
        "    if len(contours) > 0 and i < len(scores):\n",
        "        c = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        cv2.putText(\n",
        "            overlay,\n",
        "            f'{float(scores[i]):.2f}',\n",
        "            (x, max(0, y - 5)),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.4,\n",
        "            (255, 255, 255),\n",
        "            1,\n",
        "            cv2.LINE_AA,\n",
        "        )\n",
        "\n",
        "cv2.imwrite(str(OVERLAY_PATH), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
        "cv2.imwrite(str(SEM_MASK_PATH), sem_map)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img_rgb)\n",
        "plt.title('Input')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(overlay)\n",
        "plt.title('Segmentation Overlay')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f'Saved overlay: {OVERLAY_PATH}')\n",
        "print(f'Saved semantic mask: {SEM_MASK_PATH}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae45e345",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = {\n",
        "    'input_image': str(INPUT_IMAGE_PATH),\n",
        "    'config': str(CONFIG_PATH),\n",
        "    'checkpoint': str(CHECKPOINT_PATH),\n",
        "    'image_size': [int(H), int(W)],\n",
        "    'semantic_classes': [int(x) for x in np.unique(sem_map)],\n",
        "    'instance_count': int(len(masks)),\n",
        "    'score_mean': float(scores.mean()) if len(scores) > 0 else None,\n",
        "    'score_max': float(scores.max()) if len(scores) > 0 else None,\n",
        "    'overlay_path': str(OVERLAY_PATH),\n",
        "    'semantic_mask_path': str(SEM_MASK_PATH),\n",
        "}\n",
        "\n",
        "with SUMMARY_PATH.open('w', encoding='utf-8') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(json.dumps(summary, indent=2))\n",
        "print(f'Saved summary: {SUMMARY_PATH}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
