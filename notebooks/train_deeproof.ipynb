{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† DeepRoof-2026: Master Training Lab\n",
    "\n",
    "### üõ† Step 1: Super-Nuclear Environment Initialization\n",
    "This cell handles venv activation, mmseg patching, and **MMCV binary verification** (resolving '_ext' errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "import ctypes\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1. PROJECT PATHS ---\n",
    "project_root = Path(\"/workspace/roof\")\n",
    "if not project_root.exists():\n",
    "    project_root = Path(os.getcwd()).parent\n",
    "\n",
    "venv_path = project_root / \"venv\"\n",
    "if not venv_path.exists():\n",
    "    venv_path = project_root / \".venv\"\n",
    "\n",
    "if venv_path.exists():\n",
    "    lib_dir = list(venv_path.glob(\"lib/python*/site-packages\"))\n",
    "    if lib_dir:\n",
    "        if str(lib_dir[0]) not in sys.path:\n",
    "            sys.path.insert(0, str(lib_dir[0]))\n",
    "        sys.executable = str(venv_path / \"bin\" / \"python\")\n",
    "    print(f\"üêç Venv Activated: {venv_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No venv found. Using system environment.\")\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# --- 2. PRE-EMPTYIVE LIB LOADING (LD_LIBRARY_PATH FIX) ---\n",
    "def ensure_cuda_libs():\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    if not cuda_available: return\n",
    "    \n",
    "    # Search for libcudart in common places\n",
    "    search_roots = [\n",
    "        \"/usr/local/cuda/lib64/libcudart.so*\",\n",
    "        str(venv_path / \"lib/python*/site-packages/nvidia/cuda_runtime/lib/libcudart.so*\")\n",
    "    ]\n",
    "    \n",
    "    found_lib = None\n",
    "    for sr in search_roots:\n",
    "        matches = glob.glob(sr)\n",
    "        if matches:\n",
    "            found_lib = matches[0]\n",
    "            break\n",
    "            \n",
    "    if found_lib:\n",
    "        print(f\"üìç Linking CUDA Runtime: {found_lib}\")\n",
    "        try:\n",
    "            ctypes.CDLL(found_lib, mode=ctypes.RTLD_GLOBAL)\n",
    "            lib_dir = os.path.dirname(found_lib)\n",
    "            os.environ['LD_LIBRARY_PATH'] = lib_dir + os.pathsep + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "        except: pass\n",
    "    else:\n",
    "        print(\"üì¶ Installing nvidia-cuda-runtime-cu11...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nvidia-cuda-runtime-cu11\"])\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# --- 3. MMCV & MMSEG HAMMER PATCH ---\n",
    "def apply_patches():\n",
    "    print(\"ü©π Verifying MMCV & MMSeg integrity...\")\n",
    "    \n",
    "    # A. mmsegmentation assertion removal\n",
    "    target_file = None\n",
    "    try:\n",
    "        import mmseg\n",
    "        target_file = Path(mmseg.__file__).parent / \"__init__.py\"\n",
    "    except:\n",
    "        # Fallback search if import fails due to assertions\n",
    "        matches = glob.glob(str(venv_path / \"lib/python*/site-packages/mmseg/__init__.py\"))\n",
    "        if matches: target_file = Path(matches[0])\n",
    "    \n",
    "    if target_file and target_file.exists():\n",
    "        with open(target_file, 'r') as f: content = f.read()\n",
    "        if \"assert (mmcv_min_version\" in content:\n",
    "            print(f\"üî• Deleting assertions in {target_file}\")\n",
    "            unlocked = \"\"\"# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import mmcv\n",
    "import mmengine\n",
    "from mmengine.utils import digit_version\n",
    "from .version import __version__, version_info\n",
    "MMCV_MIN = '2.0.0rc4'\n",
    "MMCV_MAX = '2.2.0'\n",
    "MMENGINE_MIN = '0.7.1'\n",
    "MMENGINE_MAX = '1.0.0'\n",
    "mmcv_min_version = digit_version(MMCV_MIN)\n",
    "mmcv_max_version = digit_version('9.9.9') # OVERRIDE by DeepRoof\n",
    "mmcv_version = digit_version(mmcv.__version__)\n",
    "mmengine_min_version = digit_version(MMENGINE_MIN)\n",
    "mmengine_max_version = digit_version('9.9.9') # OVERRIDE by DeepRoof\n",
    "mmengine_version = digit_version(mmengine.__version__)\n",
    "__all__ = ['__version__', 'version_info', 'digit_version']\n",
    "\"\"\"\n",
    "            with open(target_file, 'w') as f: f.write(unlocked)\n",
    "            return False # Restart needed\n",
    "\n",
    "    # B. MMCV Extension Check\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            import mmcv\n",
    "            from mmcv.ops import point_sample\n",
    "            print(\"‚úÖ MMCV Extensions (Ops) verified.\")\n",
    "        except (ImportError, ModuleNotFoundError) as e:\n",
    "            print(f\"‚ùå MMCV Ops Error: {e}\")\n",
    "            print(\"üîÑ Reinstalling MMCV Binary for CUDA 11.8 / Torch 2.1...\")\n",
    "            # Force uninstall broken version\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"mmcv\"], check=False)\n",
    "            # Install known-good binary for this container's architecture\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"mmcv==2.2.0\", \"-f\", \"https://download.openmmlab.com/mmcv/dist/cu118/torch2.1/index.html\"])\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "if ensure_cuda_libs() and apply_patches():\n",
    "    print(f\"üöÄ System Ready | Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è DISK UPDATED. PLEASE RESTART KERNEL NOW.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 1. Dataset Preview\n",
    "\n",
    "Visualize the **OmniCity** satellite imagery and ground truth **Masks** + **Surface Normals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_dataset(num_samples=3):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    \n",
    "    data_path = project_root / \"data/OmniCity\"\n",
    "    train_file = data_path / 'train.txt'\n",
    "    \n",
    "    if not train_file.exists():\n",
    "        print(f\"‚ùå Multi-task training data not found at {data_path}.\")\n",
    "        return\n",
    "        \n",
    "    with open(train_file, 'r') as f:\n",
    "        sample_ids = [line.strip() for line in f.readlines()[:num_samples]]\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    for i, sid in enumerate(sample_ids):\n",
    "        img = cv2.cvtColor(cv2.imread(str(data_path / 'images' / (sid + '.jpg'))), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(str(data_path / 'masks' / (sid + '.png')), cv2.IMREAD_UNCHANGED)\n",
    "        mask_vis = cv2.applyColorMap(((mask % 20) * 12).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        \n",
    "        axes[i, 0].imshow(img); axes[i, 0].set_title(sid); axes[i, 0].axis('off')\n",
    "        axes[i, 1].imshow(mask_vis); axes[i, 1].set_title(\"Mask\"); axes[i, 1].axis('off')\n",
    "        \n",
    "        norm_path = data_path / 'normals' / (sid + '.npy')\n",
    "        if norm_path.exists():\n",
    "            normals = np.load(str(norm_path))\n",
    "            axes[i, 2].imshow(((normals + 1) * 127.5).astype(np.uint8))\n",
    "        axes[i, 2].set_title(\"Normals\"); axes[i, 2].axis('off')\n",
    "        \n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "preview_dataset(num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Scratch Training Configuration (Epoch-Based)\n",
    "\n",
    "We are using the **MASTER EPOCH-BASED SCRATCH PROFILE**:\n",
    "- **Duration**: 150 Epochs (~160k steps).\n",
    "- **Val Interval**: Every 1 Epoch (Reports results per-epoch).\n",
    "- **No Pre-Training**: `load_from = None`.\n",
    "- **Checkpoints**: Interval snapshots every 5 epochs + `best_mIoU.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "CONFIG_PATH = str(project_root / \"configs/deeproof_scratch_swin_L.py\")\n",
    "WORK_DIR = str(project_root / \"work_dirs/swin_l_scratch_v1\")\n",
    "\n",
    "cfg = Config.fromfile(CONFIG_PATH)\n",
    "cfg.work_dir = WORK_DIR\n",
    "cfg.data_root = str(project_root / \"data/OmniCity/\")\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "\n",
    "print(f\"üèÜ MASTER SCRATCH CONFIG LOADED\")\n",
    "print(f\"üî• Max Epochs: {cfg.train_cfg.max_epochs}\")\n",
    "print(f\"üìâ Initial LR: {cfg.optimizer.lr}\")\n",
    "print(f\"üìä Reporting Interval: Every Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 3. Kickoff Training\n",
    "\n",
    "This will invoke the `mmengine.Runner` and begin the full model convergence process. **Detailed stats will print to this output at the end of every epoch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "print(f\"üöÄ Starting Master Trainer on: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "\n",
    "runner = Runner.from_cfg(cfg)\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 4. Monitoring & Metrics\n",
    "\n",
    "Run this cell during or after training to visualize performance trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_logs(log_path):\n",
    "    if not os.path.exists(log_path):\n",
    "        print(\"üïí No logs found yet.\")\n",
    "        return\n",
    "        \n",
    "    iters, losses, miou = [], [], []\n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if 'loss' in data:\n",
    "                iters.append(data.get('iter', 0))\n",
    "                losses.append(data['loss'])\n",
    "            if 'mIoU' in data:\n",
    "                miou.append(data['mIoU'])\n",
    "                \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iters, losses, label='Loss')\n",
    "    plt.title(\"Training Progress\"); plt.show()\n",
    "\n",
    "# log_json = glob.glob(os.path.join(WORK_DIR, \"*/vis_data/scalars.json\"))\n",
    "# if log_json: plot_training_logs(log_json[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
