{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† DeepRoof-2026: Master Training Lab\n",
    "\n",
    "### üõ† Step 1: System-Level Environment Initialization\n",
    "This cell handles **MMCV Source Compilation** (for Torch 2.4+), **MMSegmentation Repair**, and **CUDA Linking** directly in the system environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "import ctypes\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print('üõ∞ Initializing DeepRepair Protocol V6 (Comprehensive)...')\n",
    "\n",
    "# --- 1. PATH RESOLUTION (NO VENV) ---\n",
    "project_root = Path('/workspace/roof')\n",
    "if not project_root.exists():\n",
    "    project_root = Path(os.getcwd()).parent\n",
    "\n",
    "# Add project root to sys.path if not present\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    \n",
    "print(f'üìÇ Project Root: {project_root}')\n",
    "print(f'üêç Python: {sys.executable}')\n",
    "\n",
    "# --- 2. NUCLEAR CUDA LINKER (System Scan) ---\n",
    "def nuclear_cuda_fix():\n",
    "    if not torch.cuda.is_available():\n",
    "        print('‚ùÑÔ∏è CPU Mode: Skipping CUDA linking.')\n",
    "        return True\n",
    "\n",
    "    print('üîç Searching for libcudart.so...')\n",
    "    # Common locations in containers\n",
    "    search_patterns = [\n",
    "        '/usr/local/cuda*/lib64/libcudart.so*',\n",
    "        '/usr/lib/x86_64-linux-gnu/libcudart.so*',\n",
    "        '/usr/lib/libcudart.so*'\n",
    "    ]\n",
    "    \n",
    "    found_lib = None\n",
    "    for pattern in search_patterns:\n",
    "        matches = glob.glob(pattern)\n",
    "        if matches:\n",
    "            # Prefer specific version if multiple\n",
    "            found_lib = sorted(matches)[-1]\n",
    "            break\n",
    "            \n",
    "    if found_lib:\n",
    "        print(f'üìç Found linking target: {found_lib}')\n",
    "        try:\n",
    "            ctypes.CDLL(found_lib, mode=ctypes.RTLD_GLOBAL)\n",
    "            print('‚úÖ CUDA Runtime force-loaded.')\n",
    "        except Exception as e:\n",
    "            print(f'‚ö†Ô∏è Force-load warning: {e}')\n",
    "    else:\n",
    "        print('‚ö†Ô∏è Could not find libcudart.so in standard paths. Assuming built-in.')\n",
    "    return True\n",
    "\n",
    "# --- 3. MMCV SOURCE COMPILER (Torch 2.4+) ---\n",
    "def match_mmcv_to_torch():\n",
    "    torch_ver = torch.__version__\n",
    "    print(f'üîç Detected: Torch {torch_ver}')\n",
    "    \n",
    "    mmcv_ok = False\n",
    "    try:\n",
    "        import mmcv\n",
    "        from mmcv.ops import point_sample\n",
    "        print('‚úÖ MMCV is fully functional.')\n",
    "        mmcv_ok = True\n",
    "    except (ImportError, ModuleNotFoundError) as e:\n",
    "        print(f'‚ùå MMCV Error: {e}')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Unknown MMCV Error: {e}')\n",
    "\n",
    "    if mmcv_ok: return True\n",
    "\n",
    "    # Logic determines remediation\n",
    "    print('üîÑ Attempting Repair...')\n",
    "\n",
    "    # Check for bleeding edge torch\n",
    "    is_bleeding_edge = False\n",
    "    if '+' in torch_ver: \n",
    "        base_ver = torch_ver.split('+')[0]\n",
    "    else:\n",
    "        base_ver = torch_ver\n",
    "        \n",
    "    major, minor = map(int, base_ver.split('.')[:2])\n",
    "    if major >= 2 and minor >= 4:\n",
    "        is_bleeding_edge = True\n",
    "\n",
    "    if is_bleeding_edge:\n",
    "        print('‚ö†Ô∏è Bleeding-edge Torch (>=2.4) detected. BINARY WHEELS DO NOT EXIST.')\n",
    "        print('üõ† Starting SOURCE COMPILATION (approx 5-10 mins)...')\n",
    "        \n",
    "        # Cleaning old\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'mmcv'], check=False)\n",
    "        \n",
    "        mmcv_dir = project_root / 'mmcv-source'\n",
    "        if mmcv_dir.exists(): shutil.rmtree(mmcv_dir)\n",
    "        \n",
    "        # Clone\n",
    "        subprocess.check_call(['git', 'clone', '-b', 'v2.2.0', 'https://github.com/open-mmlab/mmcv.git', str(mmcv_dir)])\n",
    "        \n",
    "        # Compile\n",
    "        env = os.environ.copy()\n",
    "        env['MMCV_WITH_OPS'] = '1'\n",
    "        env['FORCE_CUDA'] = '1'\n",
    "        env['MAX_JOBS'] = '8'\n",
    "        \n",
    "        print('‚è≥ Compiling... check terminal for details if stuck.')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '.'], cwd=str(mmcv_dir), env=env)\n",
    "        print('‚úÖ Compilation Complete.')\n",
    "        shutil.rmtree(mmcv_dir)\n",
    "        return False\n",
    "    else:\n",
    "         print('‚ÑπÔ∏è Standard Torch detected. Trying MIM install.')\n",
    "         subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-U', 'openmim'])\n",
    "         subprocess.check_call([sys.executable, '-m', 'mim', 'install', 'mmcv>=2.0.0'])\n",
    "         return False\n",
    "\n",
    "# --- 4. MMSEGMENTATION CHECK & REPAIR ---\n",
    "def check_mmseg():\n",
    "    print('üîç Checking MMSegmentation installation...')\n",
    "    try:\n",
    "        import mmseg\n",
    "        print(f'   MMSeg version: {mmseg.__version__}')\n",
    "        try:\n",
    "            from mmseg.models.segmentors.mask2former import Mask2Former  # noqa: F401\n",
    "            print('‚úÖ Mask2Former segmentor is available.')\n",
    "            return True\n",
    "        except ImportError:\n",
    "            try:\n",
    "                from mmseg.models.segmentors import Mask2Former  # noqa: F401\n",
    "                print('‚úÖ Mask2Former segmentor is available.')\n",
    "                return True\n",
    "            except ImportError:\n",
    "                from mmseg.models.segmentors import EncoderDecoder  # noqa: F401\n",
    "                from mmseg.models.decode_heads import Mask2FormerHead  # noqa: F401\n",
    "                print('‚ÑπÔ∏è Mask2Former segmentor not exported by this mmseg build; using EncoderDecoder compatibility path.')\n",
    "                return True\n",
    "\n",
    "    except (ImportError, ModuleNotFoundError) as e:\n",
    "        print(f'‚ùå MMSegmentation Issue: {e}')\n",
    "        print('üîÑ Reinstalling MMSegmentation via MIM...')\n",
    "        \n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'mmsegmentation'], check=False)\n",
    "        subprocess.check_call([sys.executable, '-m', 'mim', 'install', 'mmsegmentation>=1.2.2'])\n",
    "        print('‚úÖ Reinstall complete. PLEASE RESTART KERNEL.')\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f'‚ö†Ô∏è Unknown MMSeg error: {e}')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# --- 5. SAFETY NOTE ---\n",
    "def patch_assertions():\n",
    "    print('‚ÑπÔ∏è Skipping site-packages patching for mmseg/__init__.py (safer and reproducible).')\n",
    "    print('   If mmcv/mmseg versions are incompatible, reinstall matching versions instead of editing package files.')\n",
    "    return True\n",
    "\n",
    "if nuclear_cuda_fix() and match_mmcv_to_torch():\n",
    "    if check_mmseg():\n",
    "        patch_assertions()\n",
    "        print('üöÄ System Ready.')\n",
    "    else:\n",
    "        print('\\n‚ö†Ô∏è  MMSEG UPDATED. PLEASE RESTART KERNEL.')\n",
    "else:\n",
    "    print('\\n‚ö†Ô∏è  ENVIRONMENT UPDATED. PLEASE RESTART KERNEL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 1. Dataset Preview\n",
    "\n",
    "Visualize the **OmniCity** satellite imagery and ground truth **Masks** + **Surface Normals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_dataset(num_samples=3):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    \n",
    "    data_path = project_root / 'data/OmniCity'\n",
    "    train_file = data_path / 'train.txt'\n",
    "    \n",
    "    if not train_file.exists():\n",
    "        print(f'‚ùå Multi-task training data not found at {data_path}.')\n",
    "        return\n",
    "        \n",
    "    with open(train_file, 'r') as f:\n",
    "        sample_ids = [line.strip() for line in f.readlines()[:num_samples]]\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    for i, sid in enumerate(sample_ids):\n",
    "        img = cv2.cvtColor(cv2.imread(str(data_path / 'images' / (sid + '.jpg'))), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(str(data_path / 'masks' / (sid + '.png')), cv2.IMREAD_UNCHANGED)\n",
    "        mask_vis = cv2.applyColorMap(((mask % 20) * 12).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        \n",
    "        axes[i, 0].imshow(img); axes[i, 0].set_title(sid); axes[i, 0].axis('off')\n",
    "        axes[i, 1].imshow(mask_vis); axes[i, 1].set_title('Mask'); axes[i, 1].axis('off')\n",
    "        \n",
    "        norm_path = data_path / 'normals' / (sid + '.npy')\n",
    "        if norm_path.exists():\n",
    "            normals = np.load(str(norm_path))\n",
    "            axes[i, 2].imshow(((normals + 1) * 127.5).astype(np.uint8))\n",
    "        axes[i, 2].set_title('Normals'); axes[i, 2].axis('off')\n",
    "        \n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "preview_dataset(num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Scratch Training Configuration (Epoch-Based)\n",
    "\n",
    "We are using the **MASTER EPOCH-BASED SCRATCH PROFILE**:\n",
    "- **Duration**: 150 Epochs (~160k steps).\n",
    "- **Val Interval**: Every 1 Epoch (Reports results per-epoch).\n",
    "- **No Pre-Training**: `load_from = None`.\n",
    "- **Checkpoints**: Interval snapshots every 5 epochs + `best_mIoU.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.config import Config\n",
    "\n",
    "CONFIG_PATH = str(project_root / 'configs/deeproof_scratch_swin_L.py')\n",
    "WORK_DIR = str(project_root / 'work_dirs/swin_l_scratch_v1')\n",
    "\n",
    "cfg = Config.fromfile(CONFIG_PATH)\n",
    "cfg.work_dir = WORK_DIR\n",
    "cfg.data_root = str(project_root / 'data/OmniCity/')\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "\n",
    "print(f'üèÜ MASTER SCRATCH CONFIG LOADED')\n",
    "print(f'üî• Max Epochs: {cfg.train_cfg.max_epochs}')\n",
    "print(f'üìâ Initial LR: {cfg.optimizer.lr}')\n",
    "print(f'üìä Reporting Interval: Every Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 3. Kickoff Training\n",
    "\n",
    "This will invoke the `mmengine.Runner` and begin the full model convergence process. **Detailed stats will print to this output at the end of every epoch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "print(f'üöÄ Starting Master Trainer on: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}')\n",
    "\n",
    "runner = Runner.from_cfg(cfg)\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 4. Monitoring & Metrics\n",
    "\n",
    "Run this cell during or after training to visualize performance trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_logs(log_path):\n",
    "    if not os.path.exists(log_path):\n",
    "        print('üïí No logs found yet.')\n",
    "        return\n",
    "        \n",
    "    iters, losses, miou = [], [], []\n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            if 'loss' in data:\n",
    "                iters.append(data.get('iter', 0))\n",
    "                losses.append(data['loss'])\n",
    "            if 'mIoU' in data:\n",
    "                miou.append(data['mIoU'])\n",
    "                \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(iters, losses, label='Loss')\n",
    "    plt.title('Training Progress'); plt.show()\n",
    "\n",
    "# log_json = glob.glob(os.path.join(WORK_DIR, '*/vis_data/scalars.json'))\n",
    "# if log_json: plot_training_logs(log_json[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
