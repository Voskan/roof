{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† DeepRoof-2026: Multi-Task Training Notebook\n",
    "\n",
    "Welcome to the official training environment for the **DeepRoof-2026 AI Roof Layout Engine**. \n",
    "\n",
    "This notebook allows you to:\n",
    "1. **Visualize** the OmniCity dataset labels (Instance Masks + Surface Normals).\n",
    "2. **Configure** training parameters for either **Scratch Training** or **Fine-Tuning**.\n",
    "3. **Launch** the high-performance training loop optimized for A100 GPUs.\n",
    "4. **Evaluate** and visualize model predictions on new satellite imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# --- üõ† STEP 1: SOLVE PATHS & VENV ---\n",
    "project_root = str(Path(os.getcwd()).parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# 1a. Try to activate venv if it exists\n",
    "venv_site = os.path.join(project_root, \".venv/lib/python3.11/site-packages\")\n",
    "if os.path.exists(venv_site):\n",
    "    sys.path.insert(1, venv_site)\n",
    "    print(f\"üêç Using venv at: {venv_site}\")\n",
    "\n",
    "# --- üì¶ STEP 2: AUTO-INSTALL MISSING DEPENDENCIES ---\n",
    "def install_if_missing(package, import_name=None):\n",
    "    import_name = import_name or package\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"‚úÖ {import_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package}... (This may take a minute)\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# OpenMMLab Stack\n",
    "try:\n",
    "    import mmengine\n",
    "    print(\"‚úÖ mmengine found.\")\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"openmim\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"mim\", \"install\", \"mmengine\"])\n",
    "\n",
    "try:\n",
    "    import mmseg\n",
    "    print(\"‚úÖ mmsegmentation found.\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing mmsegmentation using MIM...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"openmim\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"mim\", \"install\", \"mmsegmentation>=1.0.0\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"mim\", \"install\", \"mmcv>=2.0.0\"])\n",
    "\n",
    "install_if_missing(\"rasterio\")\n",
    "install_if_missing(\"geopandas\")\n",
    "install_if_missing(\"albumentations\")\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "# Check GPU Status\n",
    "print(f\"\\nüöÄ CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üíª Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 1. Dataset Preview\n",
    "\n",
    "Before training, let's look at what our model will see. We combine **Satellite View 1** images with **Instance Masks** (segmentation) and **Surface Normals** (geometry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_dataset(data_root, num_samples=3):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    \n",
    "    data_path = Path(data_root)\n",
    "    if not data_path.is_absolute():\n",
    "        data_path = Path(project_root) / data_path\n",
    "        \n",
    "    train_file = data_path / 'train.txt'\n",
    "    if not train_file.exists():\n",
    "        print(f\"‚ùå Could not find train.txt at {train_file}. Please run the preparation script first!\")\n",
    "        return\n",
    "        \n",
    "    with open(train_file, 'r') as f:\n",
    "        sample_ids = [line.strip() for line in f.readlines()[:num_samples]]\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    \n",
    "    for i, sid in enumerate(sample_ids):\n",
    "        img = cv2.cvtColor(cv2.imread(str(data_path / 'images' / (sid + '.jpg'))), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(str(data_path / 'masks' / (sid + '.png')), cv2.IMREAD_UNCHANGED)\n",
    "        mask_vis = cv2.applyColorMap(((mask % 20) * 12).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        \n",
    "        normals = np.load(str(data_path / 'normals' / (sid + '.npy')))\n",
    "        normals_vis = ((normals + 1) * 127.5).astype(np.uint8)\n",
    "        \n",
    "        axes[i, 0].imshow(img); axes[i, 0].set_title(sid); axes[i, 0].axis('off')\n",
    "        axes[i, 1].imshow(mask_vis); axes[i, 1].set_title(\"Mask\"); axes[i, 1].axis('off')\n",
    "        axes[i, 2].imshow(normals_vis); axes[i, 2].set_title(\"Normals\"); axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "preview_dataset(\"data/OmniCity\", num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Training Configuration\n",
    "\n",
    "### üìä Hyperparameter Overview\n",
    "| Parameter | Value | Rationale |\n",
    "| :--- | :--- | :--- |\n",
    "| **Resolution** | 1024x1024 | Highest detail for complex roof layouts. |\n",
    "| **Duration** | 20,000 iters | ~16 Epochs (Ideal for fine-tuning without overfitting). |\n",
    "| **Batch Size** | 4 per GPU | optimized for A100 40GB/80GB memory. |\n",
    "| **Optimization** | AMP + AdamW | Mixed precision for 2x speedup on A100. |\n",
    "| **Task** | Multi-Task | Learns segmentation + geometry simultaneously. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"fine-tune\" # Options: \"fine-tune\" or \"scratch\"\n",
    "CONFIG_FILE = str(Path(project_root) / \"configs/deeproof_finetune_swin_L.py\")\n",
    "WORK_DIR = str(Path(project_root) / \"work_dirs/swin_l_omnicity_v2\")\n",
    "\n",
    "cfg = Config.fromfile(CONFIG_FILE)\n",
    "cfg.work_dir = WORK_DIR\n",
    "\n",
    "cfg.data_root = str(Path(project_root) / \"data/OmniCity/\")\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "cfg.train_cfg.max_iters = 20000\n",
    "\n",
    "if MODE == \"scratch\":\n",
    "    cfg.load_from = None\n",
    "    cfg.optimizer.lr = 0.0001\n",
    "    print(\"üöÄ Configured for Training from Scratch\")\n",
    "else:\n",
    "    print(f\"üéØ Configured for Fine-tuning with weights: {cfg.load_from}\")\n",
    "\n",
    "cfg.default_hooks.checkpoint = dict(\n",
    "    type='CheckpointHook', by_epoch=False, interval=2000, save_best='mIoU', rule='greater')\n",
    "\n",
    "print(\"‚úÖ Configuration Validated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 3. Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.registry import MODELS, DATASETS\n",
    "print(f\"Registered Models: {len(MODELS.module_dict)}\")\n",
    "\n",
    "runner = Runner.from_cfg(cfg)\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 4. Visualize Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.apis import init_model, inference_model\n",
    "CHECKPOINT = os.path.join(WORK_DIR, 'best_mIoU.pth')\n",
    "\n",
    "if os.path.exists(CHECKPOINT):\n",
    "    model = init_model(CONFIG_FILE, CHECKPOINT, device='cuda:0')\n",
    "    img_path = str(Path(project_root) / \"data/OmniCity/images/some_sample.jpg\") \n",
    "    if os.path.exists(img_path):\n",
    "        result = inference_model(model, img_path)\n",
    "        print(\"Prediction Complete.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Please complete training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
